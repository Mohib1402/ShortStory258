---
# Vision-Language-Action Models for Embodied AI – A Survey Overview

📚 Short Story Assignment – CMPE 258: Deep Learning  
👨‍🏫 Professor: Vijay Eranti  
✍️ Author: Mohibkhan Pathan  

---

## 🔍 Overview

This project is a deep-dive review of the 2024 survey paper:

**Ma, Y., Song, Z., Zhuang, Y., Hao, J., & King, I.**  
*A Survey on Vision-Language-Action Models for Embodied AI.*  
[arXiv:2405.14093](https://arxiv.org/abs/2405.14093)

The paper explores **Vision-Language-Action (VLA) models**, which combine vision, language, and robotic control to enable AI agents that can operate in the real world. This repository contains all the components of my short story assignment including the article, slides, and video placeholder.

---

## 📝 Medium Article

> 📖 **Read the full article on Medium:**  
[https://medium.com/@uu7470911/vision-language-action-models-for-embodied-ai-a-survey-overview-d26f11af282c](https://medium.com/@uu7470911/vision-language-action-models-for-embodied-ai-a-survey-overview-d26f11af282c)

---

## 📊 Slide Deck

> 📈 **View on SlideShare:**  
[https://www.slideshare.net/slideshow/vision-language-action-models-for-embodied-ai-a-survey-overview/279317481](https://www.slideshare.net/slideshow/vision-language-action-models-for-embodied-ai-a-survey-overview/279317481)

> 📁 Or find the PDF in this repository: `/slides/ShortStory258.pdf`

---

## 🎥 Video Presentation

[Presentation](https://arxiv.org/abs/2405.14093)

---

## 📂 Repository Structure

```bash
.
├── README.md
├── slides/
│   └── ShortStory258.pdf
└── links/
    ├── medium_article.txt
    └── slideshare_link.txt
```

---

## 📚 Reference

Ma, Y., Song, Z., Zhuang, Y., Hao, J., & King, I. (2024).
*A Survey on Vision-Language-Action Models for Embodied AI.*
arXiv preprint [arXiv:2405.14093](https://arxiv.org/abs/2405.14093)

---

## ✅ Submission Notes

* This is an individual short story assignment for CMPE 258
* Please contact me via LinkedIn or GitHub for collaboration or discussion
